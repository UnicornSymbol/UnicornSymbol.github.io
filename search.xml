<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[zabbix low level discovery]]></title>
      <url>%2F2017%2F09%2F20%2Fzabbix%2F%20zabbix%20low%20level%20discovery%2F</url>
      <content type="text"><![CDATA[lld概述&ensp;&ensp;lld用于发现item、trigger、graph等等。我们最常用如：filesystem（如/、/home、/proc、C:、D:等），network（eth0，eth1等），例如众多服务器，难免系统以及分区会有所不同。一般存在linux和windows两种系统，linux下分区有/、/data、/proc等等，windows有C: D: E:等，A服务器有/data分区，B服务器可能有/site分区。他有什么分区，我便监控什么分区，这就是low-level discovery的功能。 lld配置创建模板省略 创建自动发现规则&ensp;&ensp;步骤为：Configuration —-&gt; Templates ——&gt; 选中之前创建好的模板名—–&gt;Create discovery rule 创建item原型&ensp;&ensp;创建好auto discovery rule后，可以通过Configuration —-&gt; Templates —-&gt; Template Redis Auto Discovery（假设模板名为该名称）—-&gt; Discovery rules —-&gt; Item prototypes —-&gt; Create item prototype 创建新的item 。 客户端配置 端口收集json化：12345678910# cat redis_port.py#!/usr/bin/env pythonimport osimport jsont=os.popen(&quot;&quot;&quot;netstat -natp|awk -F: &apos;/redis-server/&amp;&amp;/LISTEN/&#123;print $2&#125;&apos;|awk &apos;&#123;print $1&#125;&apos; &quot;&quot;&quot;)ports = []for port in t.readlines(): r = os.path.basename(port.strip()) ports += [&#123;&apos;&#123;#REDISPORT&#125;&apos;:r&#125;]print json.dumps(&#123;&apos;data&apos;:ports&#125;,sort_keys=True,indent=4,separators=(&apos;,&apos;,&apos;:&apos;)) 运行结果：1234567891011121314python redis_port.py&#123; &quot;data&quot;:[ &#123; &quot;&#123;#REDISPORT&#125;&quot;:&quot;6376&quot; &#125;, &#123; &quot;&#123;#REDISPORT&#125;&quot;:&quot;6378&quot; &#125;, &#123; &quot;&#123;#REDISPORT&#125;&quot;:&quot;6379&quot; &#125; ]&#125; zabbix_agentd.conf配置12UserParameter=redis.discovery,/etc/zabbix/redis_port.pyUserParameter=redis_stats[*],redis-cli -h 127.0.0.1 -p $1 info|grep $2|cut -d : -f2 服务端验证1234567891011121314# zabbix_get -s 127.0.0.1 -p 10050 -k redis.discovery&#123; &quot;data&quot;:[ &#123; &quot;&#123;#REDISPORT&#125;&quot;:&quot;6376&quot; &#125;, &#123; &quot;&#123;#REDISPORT&#125;&quot;:&quot;6378&quot; &#125;, &#123; &quot;&#123;#REDISPORT&#125;&quot;:&quot;6379&quot; &#125; ]&#125; 参考资料Low-level discoveryzabbix小结（六）low level discovery]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ELK(二)——性能采集工具metricbeat]]></title>
      <url>%2F2017%2F08%2F31%2Felk%2FELK(%E4%B8%89)%E2%80%94%E2%80%94%E6%80%A7%E8%83%BD%E9%87%87%E9%9B%86%E5%B7%A5%E5%85%B7metricbeat%2F</url>
      <content type="text"><![CDATA[Beats简介&ensp;&ensp;Beats是一个代理，负责采集数据发送给elasticsearch或者logstash，Beats分为四个模块可以对系统进行监控，分别为FileBeat、MetricBeat、PacketBeat、WinlogBeat，分为监控文件、系统性能、网络流量、windows系统日志。 metricbeat介绍&ensp;&ensp;metricbeat用来统计并展示系统的信息 cpu， 内存等，也可以用来采集某些服务的信息，例如MySQL、nginx、redis等。 metricbeat安装配置安装123# cd /root/elk# curl -L -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-5.5.2-x86_64.rpm# rpm -vi metricbeat-5.5.2-x86_64.rpm 配置123456789101112131415161718192021# cat /etc/metricbeat/metricbeat.yml | grep -Ev &quot;^#|^ +#|^$&quot;metricbeat.modules: #要监控的模块，有nginx、MySQL、docker等- module: system metricsets: #监控指标，要保证是模块能够提供的 - cpu - load - filesystem - fsstat - memory - network - process enabled: true #是否使能对该模块的监控，默认true period: 10s #每次执行取数据的时间间隔，如果系统无效，则每个周期会返回一个错误信息 processes: [&apos;.*&apos;] #定义一个正则表达式过滤程序output.elasticsearch: hosts: [&quot;172.26.1.65:9200&quot;] #elasticsearch地址 username: &quot;elastic&quot; #x-pack用户名 password: &quot;changeme&quot; #x-pack密码 template.name: &quot;metricbeat&quot; #模板名称 template.path: &quot;metricbeat.template.json&quot; #模板路径 template.overwrite: false #是否覆盖已经存在的template 手动加载es模板1# curl -u elastic:changeme -H &apos;Content-Type: application/json&apos; -XPUT &apos;http://172.26.1.65:9200/_template/metricbeat&apos; -d@/etc/metricbeat/metricbeat.template.json 启动metricbeat1# /etc/init.d/metricbeat start 加载kibana图形1# /usr/share/metricbeat/scripts/import_dashboards -es http://172.26.1.65:9200 -user elastic -pass changeme #指定es和x-pack用户名密码 展示 参考资料Metricbeat Referencemetricbeat实现容器监控]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ELK(二)——logstash配置和使用]]></title>
      <url>%2F2017%2F08%2F29%2Felk%2FELK(%E4%BA%8C)%E2%80%94%E2%80%94logstash%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[LogStash的Shipper和Indexer&ensp;&ensp;LogStash自身没有什么角色，只是根据不同的功能、不同的配置给出不同的称呼而已。Shipper主要是安装在需要收集的日志服务器上，其input为实际的日志源，output一般来说都是Redis(你要是不想用redis做缓存也可以用其他的);Indexer则是单独部署(可以集群)，其input是redis(shipper的output)，output则是elasticSearch搜索引擎。 LogStash配置组成&ensp;&ensp;LogStash配置文件主要由 input、output、filter、codec等区域组成，每个区域内可以定义多个插件。 inputinput用来定义日志数据的来源，即日志数据从哪里传输到logstash中。其中常见的配置如下： file：从文件系统中读取一个文件，很像UNIX命令 “tail -0a” syslog：监听514端口，按照RFC3164标准解析日志数据 redis：从redis服务器读取数据，支持channel(发布订阅)和list模式。redis一般在Logstash消费集群中作为”broker”角色，保存events队列供Logstash消费。 lumberjack：使用lumberjack协议来接收数据，目前已经改为filebeat。 filterfillter在Logstash处理链中担任中间处理组件。他们经常被组合起来实现一些特定的行为，处理匹配特定规则的事件流。常见的filter配置如下： grok：解析无规则的文字并转化为有结构的格式。Grok 是目前最好的方式来将无结构的数据转换为有结构可查询的数据。有120多种匹配规则，会有一种满足你的需要。 mutate：mutate filter允许改变输入的文档，你可以在处理事件的过程中重命名，删除，移动或者修改字段。 drop：丢弃一部分events不进行处理，例如：debug events。 clone：拷贝event，这个过程中也可以添加或移除字段。 geoip：添加地理信息(为前台kibana图形化展示使用) outputoutput是logstash处理管道的最末端组件。一个event可以在处理过程中经过多重输出，但是一旦所有的outputs都执行结束，这个event也就完成生命周期。一些常用的output配置包括： elasticsearch：如果你计划将高效的保存数据，并且能够方便和简单的进行查询，Elasticsearch是一个好的方式。 file：将event数据保存到文件中。 graphite：将event数据发送到图形化组件中，一个很流行的开源存储图形化展示的组件。http://graphite.wikidot.com/。 statsd：statsd是一个统计服务，比如技术和时间统计，通过udp通讯，聚合一个或者多个后台服务，如果你已经开始使用statsd，该选项对你应该很有用。 codeccodec是基于数据流的过滤器，它可以作为input，output的一部分配置。Codec可以帮助你轻松的分割发送过来已经被序列化的数据。流行的codecs包括： json：使用json格式对数据进行编码/解码 multiline：将汇多个事件中数据汇总为一个单一的行。比如：java异常信息和堆栈信息 实例配置解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748input &#123; file &#123; # 使用file 作为输入源 path =&gt; [ &quot;/var/log/nginx/access.log&quot; ] # 日志的路径，支持/var/log*.log，及[ &quot;/var/log/messages&quot;, &quot;/var/log/*.log&quot; ] 格式 start_position =&gt; &quot;beginning&quot; # 从文件的开始读取事件。另外还有end参数 ignore_older =&gt; 0 # 忽略早于24小时（默认值86400）的日志，设为0，即关闭该功能，以防止文件中的事件由于是早期的被logstash所忽略。 &#125;&#125;filter &#123; grok &#123; # 数据结构化转换工具 patterns_dir =&gt; [&quot;/opt/logstash/patterns&quot;] # 指定gork表达式文件路径 match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;NGINXACCESS&#125;&quot; &#125; # 匹配条件格式，将nginx日志作为message变量，并应用grok条件NGINXACCESS进行转换 &#125; geoip &#123; # 该过滤器从geoip中匹配ip字段，显示该ip的地理位置 source =&gt; &quot;clientip&quot; # ip来源字段 target =&gt; &quot;geoip&quot; # 指定插入的logstash字断目标存储为geoip database =&gt; &quot;/opt/logstash/GeoLite2-City_20170801/GeoLite2-City.mmdb&quot; # geoip数据库的存放路径 add_field =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;%&#123;[geoip][longitude]&#125;&quot; ] # 增加的字段，坐标经度 add_field =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;%&#123;[geoip][latitude]&#125;&quot; ] # 增加的字段，坐标纬度 &#125; mutate &#123; # 数据的修改、删除、类型转换 convert =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;float&quot; ] # 将坐标转为float类型 convert =&gt; [ &quot;response&quot;,&quot;integer&quot; ] # http的响应代码字段转换成 int convert =&gt; [ &quot;bytes&quot;,&quot;integer&quot; ] # http的传输字节转换成int replace =&gt; &#123; &quot;type&quot; =&gt; &quot;nginx_access&quot; &#125; # 替换一个字段 remove_field =&gt; &quot;message&quot; # 移除message 的内容，因为数据已经过滤了一份，这里不必在用到该字段了。不然会相当于存两份 &#125; date &#123; # 时间处理，该插件很实用，主要是用你日志文件中事件的事件来对timestamp进行转换 match =&gt; [ &quot;timestamp&quot;,&quot;dd/MMM/yyyy:HH:mm:ss Z&quot;] # 匹配到timestamp字段后，修改格式为dd/MMM/yyyy:HH:mm:ss Z &#125; #mutate &#123; # remove_field =&gt; &quot;timestamp&quot; # 移除timestamp字段。 #&#125;&#125;output &#123; elasticsearch &#123; # 输出到es中 hosts =&gt; [&quot;172.26.1.65:9200&quot;] # es的主机ip＋端口或者es 的FQDN＋端口 index =&gt; &quot;logstash-nginx-access-%&#123;+YYYY.MM.dd&#125;&quot; # 为日志创建索引logstash-nginx-access-＊，这里也就是kibana那里添加索引时的名称 user =&gt; &quot;elastic&quot; # x-pack插件用户名 password =&gt; &quot;changeme&quot; # x-pack插件密码 &#125; stdout &#123;codec =&gt; rubydebug&#125; # json格式输出&#125; pattern配置gork使用的是ruby正则表达式，可以参考：Ruby 正则表达式。12345# mkdir -pv /opt/logstash/patterns]# cat /opt/logstash/patterns/nginx NGUSERNAME [a-zA-Z\.\@\-\+_%]+NGUSER %&#123;NGUSERNAME&#125;NGINXACCESS %&#123;IPORHOST:clientip&#125; - %&#123;NOTSPACE:remote_user&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \&quot;(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|%&#123;DATA:rawrequest&#125;)\&quot; %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QS:referrer&#125; %&#123;QS:agent&#125; \&quot;(?: %&#123;IPV4:http_x_forwarded_for&#125;|-)\&quot; geoip配置logstash5依赖于geolite2数据库。1234# wget http://geolite.maxmind.com/download/geoip/database/GeoLite2-City.tar.gz# mv GeoLite2-City.tar.gz /opt/logstash/# cd /opt/logstash/# tar xf GeoLite2-City.tar.gz 注：geoip插件的“source”字段可以是任一处理后的字段，比如“clientip”，但是字段内容却需要小心！GeoIp库内只存有公共网络上的IP信息，查询不到结果的，会直接返回null，而Logstash的GeoIp插件对null结果的处理是：“不生成对应的geoip.字段”。所以读者在测试时，如果使用了诸如127.0.0.1、172.16.0.1、182.168.0.1、10.0.0.1等内网地址，会发现没有对应输出！ 参考资料Logstash Reference利用 ELK系统分析Nginx日志并对数据进行可视化展示llogstash快速入门Logstash笔记（三）—-Filter插件及grok的正则表达式来解析日志]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ELK(一)——Centos7 elk日志分析平台搭建]]></title>
      <url>%2F2017%2F08%2F20%2Felk%2FELK(%E4%B8%80)%E2%80%94%E2%80%94Centos7%20elk%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[简介核心组成ELK由Elasticsearch、Logstash和Kibana三部分组件组成：Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。Logstash是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用。kibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。 ELK工作流程&ensp;&ensp;在需要收集日志的所有服务上部署logstash，作为logstash agent（logstash shipper）用于监控并过滤收集日志，将过滤后的内容发送到Redis，然后logstash indexer将日志收集在一起交给全文搜索服务ElasticSearch，可以用ElasticSearch进行自定义搜索通过Kibana 来结合自定义搜索进行页面展示。 架构Elasticsearch+redis：centos7.3 x86_64 IP:172.26.1.65Logstash+Kibana：centos7.3 x86_64 IP:172.26.1.64 Logstash安装安装JDK123456789# tar xf jdk-8u101-linux-x64.tar.gz -C /usr/local/# cat /etc/profile.d/java.shexport JAVA_HOME=/usr/local/jdk1.8.0_101export PATH=$PATH:$JAVA_HOME/bin# . /etc/profile.d/java.sh# java -versionjava version &quot;1.8.0_101&quot;Java(TM) SE Runtime Environment (build 1.8.0_101-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) 安装logstash 安装 1234# tar xf logstash-5.5.1.tar.gz# cd logstash-5.5.1# echo &quot;export PATH=\$PATH: /root/elk/logstash-5.5.1/bin&quot; &gt; /etc/profile.d/logstash.sh# . /etc/profile.d/logstash.sh 常用参数 12-e :指定logstash的配置信息，可以用于快速测试;-f :指定logstash的配置文件；可以用于生产环境; 启动logstash通过-e参数指定logstash的配置信息，用于快速测试，直接输出到屏幕： 1234# logstash -e &quot;input &#123;stdin&#123;&#125;&#125; output &#123;stdout&#123;&#125;&#125;&quot;... //启动信息省略hello //手动输入回车2017-08-19T08:41:27.265Z wyb-test1 hello 以json格式输出到屏幕：123456789# logstash -e &apos;input&#123;stdin&#123;&#125;&#125;output&#123;stdout&#123;codec=&gt;rubydebug&#125;&#125;&apos;...hello&#123; &quot;@timestamp&quot; =&gt; 2017-08-20T09:01:23.138Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;wyb-test1&quot;, &quot;message&quot; =&gt; &quot;hello&quot;&#125; 通过配置文件启动：1234567891011121314# cat config/logstash.conf //配置文件默认是没有的，需要手动创建input &#123; stdin &#123;&#125; &#125;output &#123; stdout &#123; codec=&gt; rubydebug &#125;&#125;# logstash -f config/logstash.conf...hello&#123; &quot;@timestamp&quot; =&gt; 2017-08-20T09:23:43.307Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;wyb-test1&quot;, &quot;message&quot; =&gt; &quot;hello&quot;&#125; logstash输出信息到redis数据库中首先确保redis数据库已经安装。1234567891011121314151617181920212223242526272829303132# cat config/logstash_to_redis.conf input &#123; stdin &#123; &#125; &#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; redis &#123; host =&gt; &apos;172.26.1.65&apos; port =&gt; 6379 data_type =&gt; &apos;list&apos; key =&gt; &apos;logstash:redis&apos; &#125;&#125;$ ./redis-cli monitor //另开一个终端开启reids动态监控# logstash -f config/logstash_to_redis.conf...world&#123; &quot;@timestamp&quot; =&gt; 2017-08-19T09:07:18.831Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;wyb-test1&quot;, &quot;message&quot; =&gt; &quot;world&quot;&#125;hello&#123; &quot;@timestamp&quot; =&gt; 2017-08-19T09:07:44.334Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;wyb-test1&quot;, &quot;message&quot; =&gt; &quot;hello&quot;&#125;$ redis-cli monitor //查看redis监控的输出OK1503133638.803386 [0 172.26.1.64:44946] &quot;rpush&quot; &quot;logstash:redis&quot; &quot;&#123;\&quot;@timestamp\&quot;:\&quot;2017-08-19T09:07:18.831Z\&quot;,\&quot;@version\&quot;:\&quot;1\&quot;,\&quot;host\&quot;:\&quot;wyb-test1\&quot;,\&quot;message\&quot;:\&quot;world\&quot;&#125;&quot;1503133664.320678 [0 172.26.1.64:44946] &quot;rpush&quot; &quot;logstash:redis&quot; &quot;&#123;\&quot;@timestamp\&quot;:\&quot;2017-08-19T09:07:44.334Z\&quot;,\&quot;@version\&quot;:\&quot;1\&quot;,\&quot;host\&quot;:\&quot;wyb-test1\&quot;,\&quot;message\&quot;:\&quot;hello\&quot;&#125;&quot; Elasticseatch安装安装elasticsearch默认不能以root用户运行，需要先创建一个elasticsearch用户：12345678910111213141516171819202122232425262728293031323334# tar xf elasticsearch-5.5.1.tar.gz -C /usr/local/# cd /usr/local/elasticsearch-5.5.1添加用户# useradd elasticsearch# chown -R elasticsearch:elasticsearch /usr/local/elasticsearch-5.5.1修改系统最大打开文件数和进程数编辑/etc/security/limits.conf文件，新增以下内容* soft nofile 65536 * hard nofile 65536 * soft nproc 65536 * hard nproc 65536修改elasticsearch配置# vim config/elasticsearch.ymlnetwork.host: 172.26.1.65# systemctl stop firewalld# setenforce 0# su - elasticsearch $ cd /usr/local/elasticsearch-5.5.1$ nohup /home/elasticsearch/elk/elasticsearch-5.5.1/bin/elasticsearch &gt; /home/elasticsearch/log/elasticsearch.log 2&gt;&amp;1 &amp;测试$ curl http://172.26.1.65:9200&#123; &quot;name&quot; : &quot;Rh8Ot71&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;aLFj06p0SgWrnK5ulAbZBQ&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;5.5.1&quot;, &quot;build_hash&quot; : &quot;19c13d0&quot;, &quot;build_date&quot; : &quot;2017-07-18T20:44:24.823Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.6.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; elasticsearch和logstash结合修改logstash配置文件：12345678910111213# vim config/logstash.conf input &#123; stdin &#123; &#125; &#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; &apos;172.26.1.65&apos; &#125; redis &#123; host =&gt; &apos;172.26.1.65&apos; port =&gt; 6379 data_type =&gt; &apos;list&apos; key =&gt; &apos;logstash:redis&apos; &#125;&#125; 启动logstash123456789# logstash -f config/logstash.conf...hello //输入&#123; &quot;@timestamp&quot; =&gt; 2017-08-21T08:32:13.362Z, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;wyb-test1&quot;, &quot;message&quot; =&gt; &quot;hello&quot;&#125; 查看elasticsearch是否收到数据12345678910111213141516171819202122232425262728293031323334353637# curl http://172.26.1.65:9200/_search?pretty&#123; &quot;took&quot; : 6, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 6, &quot;successful&quot; : 6, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 2, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;.kibana&quot;, &quot;_type&quot; : &quot;config&quot;, &quot;_id&quot; : &quot;5.5.1&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;buildNum&quot; : 15405 &#125; &#125;, &#123; &quot;_index&quot; : &quot;logstash-2017.08.21&quot;, &quot;_type&quot; : &quot;logs&quot;, &quot;_id&quot; : &quot;AV4D67lm2zeDiqIzWtWm&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;@timestamp&quot; : &quot;2017-08-21T08:32:13.362Z&quot;, &quot;@version&quot; : &quot;1&quot;, &quot;host&quot; : &quot;wyb-test1&quot;, &quot;message&quot; : &quot;hello&quot; &#125; &#125; ] &#125;&#125; Kibana安装安装12345678910111213141516# ar xf kibana-5.5.1-linux-x86_64.tar.gz -C /usr/local# cd /usr/local/kibana-5.5.1-linux-x86_64修改配置# vim config/kibana.ymlelasticsearch.url: &quot;http://172.26.1.65:9200&quot;# ./bin/kibana log [08:23:59.702] [info][status][plugin:kibana@5.5.1] Status changed from uninitialized to green - Ready log [08:23:59.811] [info][status][plugin:elasticsearch@5.5.1] Status changed from uninitialized to yellow - Waiting for Elasticsearch log [08:23:59.864] [info][status][plugin:console@5.5.1] Status changed from uninitialized to green - Ready log [08:23:59.907] [info][status][plugin:metrics@5.5.1] Status changed from uninitialized to green - Ready log [08:23:59.944] [info][status][plugin:elasticsearch@5.5.1] Status changed from yellow to green - Kibana index ready log [08:24:00.179] [info][status][plugin:timelion@5.5.1] Status changed from uninitialized to green - Ready log [08:24:00.190] [info][listening] Server running at http://localhost:5601 log [08:24:00.192] [info][status][ui settings] Status changed from uninitialized to green - Ready# netstat -tlunp | grep 5601tcp 0 0 127.0.0.1:5601 0.0.0.0:* LISTEN 20395/./bin/../node 使用nginx代理kibana并设置身份验证123456789101112131415161718192021222324# rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm# yum install nginx -y# yum install http-tools# vim /etc/nginx/conf.d/kibana.confserver &#123; listen 80; server_name 172.26.1.64; #当前主机名 auth_basic &quot;Restricted Access&quot;; auth_basic_user_file /etc/nginx/htpasswd.users; #登录验证 location / &#123; proxy_pass http://127.0.0.1:5601; #转发到kibana proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &apos;upgrade&apos;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125;# htpasswd -bc /etc/nginx/htpasswd.users admin adminAdding password for user admin# cat /etc/nginx/htpasswd.users admin:$apr1$CB/m9/Uy$/E5B0oGx6zE03XQCP4mVR/# systemctl start nginx.service# systemctl enable nginx.service 测试浏览器访问kibana能正常显示表示安装成功。 参考资料Elastic Stack and Product DocumentationELK日志分析系统Centos7_ELK5.4.1配置部署]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python3 实现salt-api登录]]></title>
      <url>%2F2017%2F06%2F01%2Fsaltstack%2Fpython3%20%E5%AE%9E%E7%8E%B0salt-api%E7%99%BB%E5%BD%95%2F</url>
      <content type="text"><![CDATA[1234567891011import urllib.request, urllib.parseimport sslheaders = &#123;&apos;X-Auth-Token&apos;:&apos;&apos;&#125;params = urllib.parse.urlencode(&#123;&apos;username&apos;:&apos;saltapi&apos;, &apos;password&apos;:&apos;123456&apos;, &apos;eauth&apos;:&apos;pam&apos;&#125;)obj = urllib.parse.unquote(params)req = urllib.request.Request(&apos;https://192.168.229.128:8888/login&apos;, obj.encode(), headers)context = ssl._create_unverified_context()res = urllib.request.urlopen(rq,context=context)res.read()b&apos;&#123;&quot;return&quot;: [&#123;&quot;perms&quot;: [&quot;.*&quot;], &quot;start&quot;: 1495546657.7008209, &quot;token&quot;: &quot;5137075130b267800afd7c2dbfd5868b7e89b786&quot;, &quot;expire&quot;: 1495589857.7008221, &quot;user&quot;: &quot;saltapi&quot;, &quot;eauth&quot;: &quot;pam&quot;&#125;]&#125;&apos; 注: 由于salt-api使用的是自签名证书，在请求时需要传入未经验证的的上下文参数，否则会报certificate verify failed错误。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos6.5 salt-api安装和配置]]></title>
      <url>%2F2017%2F05%2F31%2Fsaltstack%2FCentos6.5%20salt-api%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[安装&ensp;&ensp;一般情况下，salt-api会使用HTTPS，首次配置成功后，使用用户名和密码登陆，获得Token，Token创建后，默认有效期是12小时，在有效期之内，使用该Token可以代替使用用户名和密码来访问API(该有效时间可在salt-master配置文件中修改)。12rpm -ivh http://mirrors.aliyun.com/epel/epel-releae-latest-6.noarch.rpmyum install salt-api -y 配置生成证书12345678910111213141516171819cd /etc/pki/tls/certsmake testcert#Enter pass phrase: 键入加密短语#Verifying - Enter pass phrase: 确认加密短语#/usr/bin/openssl req -utf8 -new -key /etc/pki/tls/private/localhost.key -x509 -days 365 -out /etc/pki/tls/certs/localhost.crt -set_serial 0#Enter pass phrase for /etc/pki/tls/private/localhost.key: 再次输入相同的加密短语#Country Name (2 letter code) [XX]:CN#State or Province Name (full name) []:Guangdong#Locality Name (eg, city) [Default City]:Shenzhen#Organization Name (eg, company) [Default Company Ltd]:#Organizational Unit Name (eg, section) []:#Common Name (eg, your name or your server&apos;s hostname) []:#Email Address []:cd ../private/openssl rsa -in localhost.key -out localhost_nopass.key#Enter pass phrase for localhost.key: 输入之前的加密短语 也可以借助salt-call命令来生成:1salt-call --local tls.create_self_signed_cert 添加用户12useradd -M -s /sbin/nologin saltapipasswd saltapi 配置salt-api12345678910111213141516mkdir -p /etc/salt/master.d/ cd /etc/salt/master.d/ touch eauth.conftouch api.conf#vi eauth.confexternal_auth: pam: saltapi: #用户 - .* #该配置文件给予saltapi用户所有模块使用权限，出于安全考虑一般只给予特定模块使用权限#vi api.confrest_cherrypy: port: 8888 ssl_crt: /etc/pki/tls/certs/localhost.crt ssl_key: /etc/pki/tls/private/localhost_nopass.key 重启服务12service salt-master restartservice salt-api restart 验证1234567891011#获取tokencurl -k https://192.168.181.15:8888/login -H &quot;Accept: application/x-yaml&quot; -d username=&apos;saltapi&apos; -d password=&apos;123456&apos; -d eauth=&apos;pam&apos;return:- eauth: pam expire: 1495586320.09008 perms: - .* start: 1495543120.0900791 token: 0fd22dfdc3062ae0ca6d708a4803a40a83e5b6b0 user: saltapi 参考资料Saltstack学习笔记——安装Salt-APISaltStack RESTful API的调用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[saltstack(四)——自动安装nginx-1.4.5实例]]></title>
      <url>%2F2017%2F05%2F12%2Fsaltstack%2Fsaltstack(%E5%9B%9B)%E2%80%94%E2%80%94%E8%87%AA%E5%8A%A8%E5%AE%89%E8%A3%85nginx-1.4.5%E5%AE%9E%E4%BE%8B%2F</url>
      <content type="text"><![CDATA[目录结构123456789101112131415161718[root@linux-node1 prod]# pwd/srv/salt/prod[root@linux-node1 prod]# tree.├── nginx│ ├── conf.sls│ ├── files│ │ ├── nginx│ │ ├── nginx-1.4.5.tar.gz│ │ ├── nginx.conf│ │ ├── nginx_log_cut.sh│ │ └── vhost.conf│ ├── init.sls│ ├── install.sls│ └── vhost.sls└── top.sls2 directories, 10 files init.sls12345[root@linux-node1 prod]# cat nginx/init.sls include: - nginx.install - nginx.conf - nginx.vhost Install.sls&ensp;&ensp;nginx编译安装，涉及文件管理、包管理、用户管理及cmd运用，其中注意的是如果使用cmd，它每次同步客户时都会执行，为了防止这一现象，使用unless可解决。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061[root@linux-node1 prod]# cat nginx/install.sls #nginx.tar.gznginx_source: file.managed: - name: /tmp/nginx-1.4.5.tar.gz - unless: test -e /tmp/nginx-1.4.5.tar.gz - source: salt://nginx/files/nginx-1.4.5.tar.gz#extractextract_nginx: cmd.run: - cwd: /tmp - names: - tar zxvf nginx-1.4.5.tar.gz - unless: test -d /tmp/nginx-1.4.5 - require: - file: nginx_source#usernginx_user: user.present: - name: nginx - uid: 1501 - createhome: False - gid_from_name: True - shell: /sbin/nologin#nginx_pkgsnginx_pkg: pkg.installed: - pkgs: - gcc - openssl-devel - pcre-devel - zlib-devel#nginx_compilenginx_compile: cmd.run: - cwd: /tmp/nginx-1.4.5 - names: - ./configure --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_gzip_static_module --http-client-body-temp-path=/usr/local/nginx/client/ --http-proxy-temp-path=/usr/local/nginx/proxy/ --http-fastcgi-temp-path=/usr/local/nginx/fcgi/ --with-poll_module --with-file-aio --with-http_realip_module --with-http_addition_module --with-http_random_index_module --with-pcre --with-http_stub_status_module - make - make install - require: - cmd: extract_nginx - pkg: nginx_pkg - unless: test -d /usr/local/nginx#cache_dircache_dir: cmd.run: - names: - mkdir -p /usr/local/nginx/&#123;client,proxy,fcgi&#125; &amp;&amp; chown -R nginx.nginx /usr/local/nginx/ - unless: test -d /usr/local/nginx/client/ - require: - cmd: nginx_compile conf.sls12345678910111213141516171819202122232425262728293031323334353637383940[root@linux-node1 prod]# cat nginx/conf.sls include: - nginx.install # 引用安装&#123;% set nginx_user = &apos;nginx&apos; + &apos; &apos; + &apos;nginx&apos; %&#125; # 设置用户变量nginx_conf: file.managed: # nginx主配置文件管理 - name: /usr/local/nginx/conf/nginx.conf - source: salt://nginx/files/nginx.conf - template: jinja - defaults: nginx_user: &#123;&#123; nginx_user &#125;&#125; num_cpus: &#123;&#123;grains[&apos;num_cpus&apos;]&#125;&#125; # 根据cpu的个数来设置nginx.conf文件nginx_service: # nginx服务管理 file.managed: - name: /etc/init.d/nginx - user: root - mode: 755 - source: salt://nginx/files/nginx cmd.run: # 将服务由chkconfig管理 - names: - /sbin/chkconfig --add nginx - /sbin/chkconfig nginx on - unless: /sbin/chkconfig --list nginx service.running: # nginx是启动状态 - name: nginx - enable: True - reload: True - watch: - file: /usr/local/nginx/conf/*.confnginx_log_cut: # nginx日志管理 file.managed: - name: /usr/local/nginx/sbin/nginx_log_cut.sh - source: salt://nginx/files/nginx_log_cut.sh cron.present: # 将日志切割脚本加入crontab定时执行 - name: sh /usr/local/nginx/sbin/nginx_log_cut.sh - user: root - minute: 10 - hour: 0 - require: - file: nginx_log_cut Nginx启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128[root@linux-node1 prod]# cat nginx/files/nginx#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15 # description: Nginx is an HTTP(S) server, HTTP(S) reverse \# proxy and IMAP/POP3 proxy server# processname: nginx# config: /usr/local/nginx/conf/nginx.conf# pidfile: /usr/local/nginx/logs/nginx.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0 nginx=&quot;/usr/local/nginx/sbin/nginx&quot;prog=$(basename $nginx) NGINX_CONF_FILE=&quot;/usr/local/nginx/conf/nginx.conf&quot; lockfile=/var/lock/subsys/nginx make_dirs() &#123; # make required directories user=`$nginx -V 2&gt;&amp;1 | grep &quot;configure arguments:&quot; | sed &apos;s/[^*]*--user=\([^ ]*\).*/\1/g&apos; -` if [ -z &quot;`grep $user /etc/passwd`&quot; ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2&gt;&amp;1 | grep &apos;configure arguments:&apos;` for opt in $options; do if [ `echo $opt | grep &apos;.*-temp-path&apos;` ]; then value=`echo $opt | cut -d &quot;=&quot; -f 2` if [ ! -d &quot;$value&quot; ]; then # echo &quot;creating&quot; $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done&#125; start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $&quot;Starting $prog: &quot; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; configtest || return $? stop sleep 1 start&#125; reload() &#123; configtest || return $? echo -n $&quot;Reloading $prog: &quot; killproc $nginx -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;&quot; exit 2esac Nginx主配置文件123456789101112131415161718192021222324252627282930313233343536373839404142[root@linux-node1 prod]# cat nginx/files/nginx.conf #user &#123;&#123; nginx_user &#125;&#125;; # 这里调用conf.sls中的配置worker_processes &#123;&#123;grains[&apos;num_cpus&apos;]&#125;&#125;;error_log logs/nginx_error.log notice;pid /usr/local/nginx/sbin/nginx.pid;worker_rlimit_nofile 65535;events &#123; use epoll; worker_connections 65535; &#125;http &#123; include mime.types; default_type application/octet-stream; charset utf-8; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 128m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; server_tokens off; client_body_buffer_size 512k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$host&quot;&apos; ; include vhost*.conf; &#125; 日志切割脚本123456789101112131415[root@linux-node1 prod]# cat nginx/files/nginx_log_cut.sh #!/bin/bashlogs_path=/usr/local/nginx/logsyesterday=`date -d &quot;yesterday&quot; +%F`mkdir -p $logs_path/$yesterdaycd $logs_pathfor nginx_logs in `ls *log`do mv $nginx_logs $&#123;yesterday&#125;/$&#123;yesterday&#125;-$&#123;nginx_logs&#125; kill -USR1 `cat /usr/local/nginx/sbin/nginx.pid`done Pillar目录123456789[root@linux-node1 pillar]# pwd/srv/pillar[root@linux-node1 pillar]# tree.├── nginx│ └── init.sls└── top.sls1 directories, 2 files Pillar配置1234567891011121314[root@linux-node1 pillar]# cat top.sls base: &apos;*&apos;: - nginx[root@linux-node1 pillar]# cat nginx/init.sls vhost: &#123;% if &apos;test8&apos; in grains[&apos;id&apos;] %&#125; //如果id中有test8字符，使用vhost_www.conf配置文件，反之使用vhost_bbs.conf配置文件 - name: www //必须加”-“形成列表,不然在后面for引用时会报错 target: /usr/local/nginx/conf/vhost_www.conf &#123;% else %&#125; - name: bbs target: /usr/local/nginx/conf/vhost_bbs.conf &#123;% endif %&#125;[root@linux-node1 pillar]# salt &apos;*&apos; saltutil.refresh_pillar vhost.sls12345678910111213141516171819[root@linux-node1 prod]# cat nginx/vhost.sls include: - nginx.install&#123;% for vhostname in pillar[&apos;vhost&apos;] %&#125;&#123;&#123;vhostname[&apos;name&apos;]&#125;&#125;: file.managed: - name: &#123;&#123;vhostname[&apos;target&apos;]&#125;&#125; - source: salt://nginx/files/vhost.conf - target: &#123;&#123;vhostname[&apos;target&apos;]&#125;&#125; - template: jinja - defaults: server_name: &#123;&#123;grains[&apos;fqdn_ip4&apos;][0]&#125;&#125; log_name: &#123;&#123;vhostname[&apos;name&apos;]&#125;&#125; - watch_in: service: nginx #可以去掉，没有定义nginx这个service，而且前面已经watch了&#123;% endfor %&#125; vhost.conf123456789101112131415161718192021222324252627[root@linux-node1 prod]# cat nginx/files/vhost.conf server &#123; listen 80; server_name &#123;&#123; server_name &#125;&#125;; # 调用vhost.sls中配置 index index.html index.htm ; root html; #location ~ .*\.(php|php5)?$ # &#123; # try_files $uri =404; # fastcgi_pass unix:/tmp/php-cgi.sock; # fastcgi_index index.php; # include fcgi.conf; # &#125; location /status &#123; stub_status on; &#125; location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 30d; &#125; location ~ .*\.(js|css)?$ &#123; expires 1d; &#125; access_log logs/&#123;&#123; log_name &#125;&#125;-access.log main; &#125; 执行12[root@linux-node1 prod]# salt &apos;*&apos; state.highstate env=prod test=True #先测试，没错误再执行[root@linux-node1 prod]# salt &apos;*&apos; state.highstate env=prod]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[saltstack(三)——State组件]]></title>
      <url>%2F2017%2F05%2F11%2Fsaltstack%2Fsaltstack(%E4%B8%89)%E2%80%94%E2%80%94State%E7%BB%84%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[state&ensp;&ensp;State是salstack最核心的功能，通过预先定制好的sls(salt state file)文件对被控主机进行状态管理，支持包括程序包(pkg)、文件(file)、网络配置(network)、系统服务(service)、系统用户(user)等。 state定义state定义是通过sls文件进行描述的，支持YAML语法，定义规则如下：123$ID: $State - $state: states $ID：定义state名称，通常采用与描述对象保持一致的方法，如apache,nginx等$State：管理对象的类型$state: states：定制对象的状态 state的使用&ensp;&ensp;state的入口文件和pillar一样，都是top.sls,但state要求sls文件必须存放在saltstack base定义的目录下，默认为/srv/salt。在top.sls中引用二级配置有2种方式，一种是直接引用，另一种是创建二级目录，再引用目录中的init.sls文件。为了规范起见，建议用第二种。下面是一个根据不同操作系统类型部署Apache的例子。 定义pillar123456789101112131415161718192021222324252627[root@linux-node1 ~]# cat /srv/pillar/top.sls base: &apos;*&apos;: - data - apache[root@linux-node1 ~]# cat /srv/pillar/apache/init.sls pkgs: &#123;% if grains[&apos;os_family&apos;] == &apos;Debian&apos; %&#125; apache: apache2 &#123;% elif grains[&apos;os_family&apos;] == &apos;RedHat&apos; %&#125; apache: httpd &#123;% elif grains[&apos;os&apos;] == &apos;Arch&apos; %&#125; apache: apache &#123;% endif %&#125;[root@linux-node1 ~]# salt &apos;*&apos; pillar.data pkgslinux-node2: ---------- pkgs: ---------- apache: httpdlinux-node1: ---------- pkgs: ---------- apache: httpd 定义state12345678910111213[root@linux-node1 ~]# cat /srv/salt/top.slsbase: &apos;*&apos;:- apache[root@linux-node1 ~]# cat /srv/salt/apache/init.slsapache: pkg: - installed - name: &#123;&#123; pillar[&apos;pkgs&apos;][&apos;apahce&apos;] &#125;&#125; service.running - name: &#123;&#123; pillar[&apos;pkgs&apos;][&apos;apache&apos;] &#125;&#125; - require: - pkg: &#123;&#123; pillar[&apos;pkgs&apos;][&apos;apache&apos;]&#125;&#125; 执行state123456789101112131415161718192021222324252627282930313233343536[root@linux-node1 ~]# salt &apos;linux-node2&apos; state.sls apache test=Truelinux-node2:---------- ID: apache-install Function: pkg.installed Name: httpd Result: True Comment: Package httpd is already installed. Started: 20:57:17.331685 Duration: 1078.642 ms Changes: ---------- ID: apache-install Function: pkg.installed Name: httpd-devel Result: True Comment: Package httpd-devel is already installed. Started: 20:57:18.410806 Duration: 1.841 ms Changes: ---------- ID: apache-service Function: service.running Name: httpd Result: True Comment: Service httpd is already enabled, and is in the desired state Started: 20:57:18.413696 Duration: 69.99 ms Changes: Summary------------Succeeded: 3Failed: 0------------Total states run: 3 注：执行state时一般使用salt ‘linux-node2’ state.sls apache命令，当然也可以执行salt ‘linux-node2’ state.highstate匹配所有的state.sls模块。test=True指测试安装，并不进行实际操作。 state执行顺序&ensp;&ensp;state执行时无序，无序是指我们写的sls是无序的，salt为了保证每次执行顺序是一样的，就加入了state order，在这之前先看看高级数据(high data)和低级数据(low data)，高级数据指的就是我们编写sls文件的数据，低级数据就是经过render和parser编译过的数据。查看highdata：1[root@linux-node1 ~]# salt &apos;*&apos; state.show_highstate 查看lowdata：12345[root@linux-node1 ~]# salt &apos;*&apos; state.show_lowstate… order: 10000.0001… 通过查看lowstate我们发现里面有有一个字段order，因为salt默认会自动设置order，从10000开始。可以通过设置master配置文件参数state_auto_order: False来关闭。Order的设定：1). include：被include的文件order靠前，先执行2). 手动定义order字段，order的数字越小先执行，从1开始，-1是最后执行，如：1234apache: pkg: - installed - order: 1 参考资料saltstack 全面介绍]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[saltstack(二)——saltstack数据系统]]></title>
      <url>%2F2017%2F05%2F09%2Fsaltstack%2Fsaltstack(%E4%BA%8C)%E2%80%94%E2%80%94saltstack%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%2F</url>
      <content type="text"><![CDATA[grains组件&ensp;&ensp;grains组件是saltstack最重要的组件之一，grains的作用是收集被控端主机的基本信息，这些信息通常都是一些静态类的数据，包括CPU、内核、操作系统、虚拟化等，在服务器端可以根据这些信息进行灵活定制，管理员利用这些信息对不同业务进行个性化配置。 grains常用操作命令获取所有主机的grains项信息：1[root@linux-node1 ~]# salt &quot;*&quot; grains.ls 查看grains所有信息：1[root@linux-node1 ~]# salt &quot;*&quot; grains.items 查看某个grains项信息：1[root@linux-node1 ~]# salt &quot;*&quot; grains.item os 自定义grains数据&ensp;&ensp;自定义grains数据有2中方法，一种为在被控主机定制配置文件，另一种通过主控端扩展模块API实现，区别是模块更灵活，可以通过Python编程动态定义，而配置文件只适合相对固定的键与值。 被控端主机定制grains数据配置文件定制的路径为/etc/salt/minion，参数为default_include: minion.d/*.conf。 123456789101112131415161718[root@linux-node2 ~]# cat /etc/salt/minion.d/hostinfo.confgrains: roles: - webserver - memcache deployment: datacenter4 cabinet: 13[root@linux-node2 ~]# service salt-minion restart #重启生效[root@linux-node1 ~]# salt &quot;linux-node2&quot; grains.item roles deployment cabinetlinux-node2: ---------- cabinet: 13 deployment: datacenter4 roles: - webserver - memcache 主控端扩展模块定制grains数据首先在主控端编写Python代码，然后将该Python文件同步到被控主机，最后刷新生效。Python代码存放的位置为base目录(/etc/salt/master配置文件的file_roots项)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@linux-node1 ~]# install -d /srv/salt/_grains[root@linux-node1 ~]# cat /srv/salt/_grains/sysprocess.pyimport os,sys,commandsdef Grains_openfile(): grains = &#123;&#125; # init default value _open_file=65536 try: getulimit=commands.getstatusoutput(&apos;source /etc/profile;ulimit -n&apos;) except Exception,e: pass if getulimit[0]==0: _open_file=int(getulimit[1]) grains[&apos;max_open_file&apos;] = _open_file return grains[root@linux-node1 ~]# salt &apos;linux-node2&apos; saltutil.sync_all #同步模块linux-node2: ---------- beacons: grains: - grains.sysprocess modules: output: renderers: returners: sdb: states:utils:# 同步后将在被控端生成以下2个文件[root@linux-node2 ~]# ls /var/cache/salt/minion/extmods/grains/sysprocess.py/var/cache/salt/minion/extmods/grains/sysprocess.py #扩展模块文件最终存放位置[root@linux-node2 ~]# ls /var/cache/salt/minion/files/base/_grains/sysprocess.py /var/cache/salt/minion/files/base/_grains/sysprocess.py #临时存放位置[root@linux-node1 ~]# salt &apos;linux-node2&apos; sys.reload_modules #刷新模块linux-node2:True# 刷新后将在被控端生成一个编译后的字节码文件[root@linux-node2 ~]# ls /var/cache/salt/minion/extmods/grains/sysprocess.pyc/var/cache/salt/minion/extmods/grains/sysprocess.pyc[root@linux-node1 ~]# salt &apos;linux-node2&apos; grains.item max_open_file #测试linux-node2: ---------- max_open_file: 65535 pillar组件&ensp;&ensp;pillar组件也是saltstack最重要的组件之一，其作用是定义与被控主机相关的任何数据，定义好的数据可以被其他组件使用，如模板、state、API等。在pillar中定义的数据与不同业务特性的被控主机相关联，这样不同被控主机只能看到自己匹配的数据，因此pillar安全性很高，适用于一些较敏感的数据。 pillar的定义 Saltstack默认将主控端配置文件中的所有数据都定义到pillar中，而且对所有被控主机开放，可以通过修改/etc/salt/amster配置中的pillar_opts: True或False来定义是否开启此功能，修改后执行salt ‘*’ pillar.data来观察效果。 123456789101112131415161718192021222324252627[root@linux-node1 ~]# salt &quot;*&quot; pillar.datalinux-node2: ---------- master: ---------- __role: master auth_mode: 1 auto_accept: True cache_sreqs: True cachedir: /var/cache/salt/master cli_summary: False client_acl: ---------- client_acl_blacklist: ---------- cluster_masters: cluster_mode: paranoid con_cache: False …… sls文件定义Pillar支持在sls文件中定义数据，格式必须符合YAML规范，与saltstack的state组件十分相似，容易混淆。 123456789101112131415161718192021222324252627[root@linux-node1 ~]# cat /etc/salt/master #修改主配置文件…pillar_roots: base: - /srv/pillar…[root@linux-node1 ~]# install -d /srv/pillar[root@linux-node1 ~]# cat /srv/pillar/top.slsbase: &apos;*&apos;: - data[root@linux-node1 ~]# cat /srv/pillar/data.slsappname: websiteflow: maxconn: 30000 maxmem: 6G[root@linux-node1 ~]# salt &apos;linux-node2&apos; pillar.data appname flow #测试linux-node2: ---------- appname: website flow: ---------- maxconn: 30000 maxmem: 6G 注：如果结果不符合预期，可以执行salt ‘*’ saltutil.refresh_pillar刷新被控主机pillar数据。 grains和pillar区别grains：静态数据，minion启动时收集，也可以用saltutil.sync_grains进行刷新。Pillar：动态数据，在master端定义指定给对应的minion，可以使用saltutil.refresh_pillar刷新。 参考资料saltstack 全面介绍]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[saltstack(一)——saltstack安装配置]]></title>
      <url>%2F2017%2F05%2F08%2Fsaltstack%2Fsaltstack(%E4%B8%80)%E2%80%94%E2%80%94saltstack%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[Saltstack简介&ensp;&ensp;SaltStack是一个服务器基础架构集中化管理平台，具备配置管理、远程执行、监控等功能，一般可以理解为简化版的puppet和加强版的func。SaltStack基于Python语言实现，结合轻量级消息队列（ZeroMQ）与Python第三方模块（Pyzmq、PyCrypto、Pyjinjia2、python-msgpack和PyYAML等）构建。&ensp;&ensp;通过部署SaltStack环境，我们可以在成千上万台服务器上做到批量执行命令，根据不同业务特性进行配置集中化管理、分发文件、采集服务器数据、操作系统基础及软件包管理等，SaltStack是运维人员提高工作效率、规范业务配置与操作的利器。 Saltstack安装测试环境Master：192.168.229.128(linux-node1)Minion：192.168.229.128(linux-node1)，192.168.229.129(linux-node2) 安装epel源1[root@linux-node1 ~]# rpm -ivh http://mirrors.aliyun.com/epel/epel-releae-latest-6.noarch.rpm Master安装123[root@linux-node1 ~]# yum install salt-master -y[root@linux-node1 ~]# chkconfig salt-master on[root@linux-node1 ~]# service salt-master start Minion安装123[root@linux-node1 ~]# yum install salt-minion –y[root@linux-node1 ~]# chkconfig salt-minion on[root@linux-node1 ~]# service salt-minion start 配置saltstack1234567891011121314151617[root@linux-node1 ~]# vim /etc/salt/master# 绑定master IPInterface: 192.168.229.128# 自动认证，避免手动运行salt-key来确认证书信任auto_accept: True# 指定saltstack文件根目录file_roots: base: - /srv/salt[root@linux-node1 ~]# mkdir /srv/salt[root@linux-node1 ~]# service salt-master restart[root@linux-node1 ~]# vim /etc/salt/minion# 指定master主机地址master: 192.168.229.128# 指定被控主机识别ID，建议使用操作系统主机名来配置，默认通过Python方法socket.getfqdn()去获取fqdn名。id: linux-node1[root@linux-node1 ~]# service salt-minion restart 参考资料Saltstack自动化操作记录（1）-环境部署]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django book学习笔记(三)——模型]]></title>
      <url>%2F2017%2F04%2F13%2Fdjango%2FDjango_book%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%89)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[模型简介&ensp;&ensp;模型，即数据存取层。该层处理与数据相关的所有事务：如何存取、如何验证有效性、包含哪些行为以及数据之间的关系等。它能有效的避免我们将数据库操作硬编码于代码中，并且方便在不同数据库之间进行迁移。 数据库设置打开settings.py配置文件，找到数据库配置DATABASES,例如：12345678910DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, # 使用哪个数据库引擎 &apos;NAME&apos;: &apos;djangodb&apos;, # 数据库名称 &apos;USER&apos;: &apos;django&apos;, # 用哪个用户连接数据库 &apos;PASSWORD&apos;: &apos;django&apos;, # 用户密码 &apos;HOST&apos;: &apos;localhost&apos;, # 数据库服务器监听地址 &apos;PORT&apos;: &apos;3306&apos;, # 数据库服务器监听端口 &#125;&#125; 创建应用程序1python manage.py startapp books 注：系统对app有一个约定：如果你使用了Django的数据库层(模型)，你必须创建一个django app，模型必须存放在apps中。 模型定义第一步是用Python代码来描述它们。打开由startapp命令创建的models.py并输入下面的内容：1234567891011121314151617181920from django.db import modelsclass Publisher(models.Model): name = models.CharField(max_length=30) address = models.CharField(max_length=50) city = models.CharField(max_length=60) state_province = models.CharField(max_length=30) country = models.CharField(max_length=50) website = models.URLField()class Author(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=40) email = models.EmailField()class Book(models.Model): title = models.CharField(max_length=100) authors = models.ManyToManyField(Author) publisher = models.ForeignKey(Publisher) publication_date = models.DateField() 首先要注意的事是每个数据模型都是django.db.models.Model的子类。它的父类Model包含了所有和数据库打交道的方法，并提供了一个简洁漂亮的定义语法。每个模型相当于单个数据库表，每个属性也是这个表中的一个字段。属性名就是字段名，它的类型例如(CharField)相当于数据库的字段类型 (例如 varchar)。 模型安装激活模型要在数据库中创建这些表，第一步是在Django项目中激活这些模型。将app添加到配置文件的已INSTALLED_APPS列表中即可完成此步骤。INSTALLED_APPS告诉 Django 项目哪些 app 处于激活状态。例如：1234567891011121314INSTALLED_APPS = ( &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.sites&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, # Uncomment the next line to enable the admin: # &apos;django.contrib.admin&apos;, # Uncomment the next line to enable admin documentation: # &apos;django.contrib.admindocs&apos;, &apos;debug_toolbar&apos;, &apos;books&apos;,) 校验模型第二步用下面的命令校验模型的有效性：1python manage.py validate 生成sql语句第三步模型确认没问题了，运行下面的命令来生成 CREATE TABLE 语句：1python manage.py sqlall books 注：sqlall 命令并没有在数据库中真正创建数据表，只是把SQL语句段打印出来。 同步模型第四步运行以下命令同步模型到数据库：1python manage.py syncdb 基本数据访问一旦你创建了模型，Django自动为这些模型提供了高级的Python API。运行python manage.py shell可以和数据库进行交互。123456789101112&gt;&gt;&gt; from books.models import Publisher&gt;&gt;&gt; p1 = Publisher(name=&apos;Apress&apos;, address=&apos;2855 Telegraph Avenue&apos;,... city=&apos;Berkeley&apos;, state_province=&apos;CA&apos;, country=&apos;U.S.A.&apos;,... website=&apos;http://www.apress.com/&apos;)&gt;&gt;&gt; p1.save()&gt;&gt;&gt; p2 = Publisher(name=&quot;O&apos;Reilly&quot;, address=&apos;10 Fawcett St.&apos;,... city=&apos;Cambridge&apos;, state_province=&apos;MA&apos;, country=&apos;U.S.A.&apos;,... website=&apos;http://www.oreilly.com/&apos;)&gt;&gt;&gt; p2.save()&gt;&gt;&gt; publisher_list = Publisher.objects.all()&gt;&gt;&gt; publisher_list[&lt;Publisher: Publisher object&gt;, &lt;Publisher: Publisher object&gt;] 注意：当你使用Django modle API创建对象时Django并未将对象保存至数据库内，除非你调用save()方法。如果需要一步完成对象的创建与存储至数据库，就使用objects.create()方法。1234&gt;&gt;&gt; p1 = Publisher.objects.create(name=&apos;Apress&apos;,... address=&apos;2855 Telegraph Avenue&apos;,... city=&apos;Berkeley&apos;, state_province=&apos;CA&apos;, country=&apos;U.S.A.&apos;,... website=&apos;http://www.apress.com/&apos;) 添加模块的字符串表现当我们打印整个publisher列表时，我们没有得到想要的有用的信息：123&gt;&gt;&gt; publisher_list = Publisher.objects.all()&gt;&gt;&gt; publisher_list[&lt;Publisher: Publisher object&gt;, &lt;Publisher: Publisher object&gt;] 只需要添加一个方法 __unicode__() 到 Publisher对象。__unicode__()方法告诉Python如何实现对象的unicode表示。1234567891011121314151617181920212223242526272829from django.db import modelsclass Publisher(models.Model): name = models.CharField(max_length=30) address = models.CharField(max_length=50) city = models.CharField(max_length=60) state_province = models.CharField(max_length=30) country = models.CharField(max_length=50) website = models.URLField() def __unicode__(self): return self.nameclass Author(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=40) email = models.EmailField() def __unicode__(self): return u&apos;%s %s&apos; % (self.first_name, self.last_name)class Book(models.Model): title = models.CharField(max_length=100) authors = models.ManyToManyField(Author) publisher = models.ForeignKey(Publisher) publication_date = models.DateField() def __unicode__(self): return self.title 为了让我们的修改生效，先退出Python Shell，然后再次运行 python manage.py shell 进入。1234&gt;&gt;&gt; from books.models import Publisher&gt;&gt;&gt; publisher_list = Publisher.objects.all()&gt;&gt;&gt; publisher_list[&lt;Publisher: Apress&gt;, &lt;Publisher: O&apos;Reilly&gt;]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django之model详解]]></title>
      <url>%2F2017%2F04%2F11%2Fdjango%2FDjango%E4%B9%8Bmodel%E8%AF%A6%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[创建表&ensp;&ensp;Django中遵循 Code Frist 的原则，即：根据代码中定义的类来自动生成数据库表。 基本结构1234567891011121314151617from django.db import models# Create your models here.class userinfo(models.Model): nid = models.AutoField(primary_key=True) username = models.CharField(max_length=32) email = models.EmailField() ip = models.GenericIPAddressField() memo = models.TextField() img = models.ImageField() usertype=models.ForeignKey("usertype",null=True,blank=True)class usertype(models.Model): name = models.CharField(max_length=32) def __str__(self): return self.name 常用字段 123456789101112131415161718192021222324252627282930313233343536373839404142models.AutoField 自增列 = int(11) 如果没有的话，默认会生成一个名称为 id 的列，如果要显示的自定义一个自增列，必须将给列设置为主键 primary_key=True。models.CharField 字符串字段 必须 max_length 参数models.BooleanField 布尔类型=tinyint(1) 不能为空，Blank=Truemodels.ComaSeparatedIntegerField 用逗号分割的数字=varchar 继承CharField，所以必须 max_lenght 参数models.DateField 日期类型 date 对于参数，auto_now = True 则每次更新都会更新这个时间；auto_now_add 则只是第一次创建添加，之后的更新不再改变。models.DateTimeField 日期类型 datetime 同DateField的参数models.Decimal 十进制小数类型 = decimal 必须指定整数位max_digits和小数位decimal_placesmodels.EmailField 字符串类型（正则表达式邮箱） =varchar 对字符串进行正则表达式models.FloatField 浮点类型 = doublemodels.IntegerField 整形models.BigIntegerField 长整形 integer_field_ranges = &#123; &apos;SmallIntegerField&apos;: (-32768, 32767), &apos;IntegerField&apos;: (-2147483648, 2147483647), &apos;BigIntegerField&apos;: (-9223372036854775808, 9223372036854775807), &apos;PositiveSmallIntegerField&apos;: (0, 32767), &apos;PositiveIntegerField&apos;: (0, 2147483647), &#125;models.IPAddressField 字符串类型（ip4正则表达式）models.GenericIPAddressField 字符串类型（ip4和ip6是可选的） 参数protocol可以是：both、ipv4、ipv6 验证时，会根据设置报错models.NullBooleanField 允许为空的布尔类型models.PositiveIntegerFiel 正Integermodels.PositiveSmallIntegerField 正smallIntegermodels.SlugField 减号、下划线、字母、数字models.SmallIntegerField 数字 数据库中的字段有：tinyint、smallint、int、bigintmodels.TextField 字符串=longtextmodels.TimeField 时间 HH:MM[:ss[.uuuuuu]]models.URLField 字符串，地址正则表达式models.BinaryField 二进制models.ImageField 图片models.FilePathField 文件 常用参数 1234567891011121314151617181920212223242526271、null=True 数据库中字段是否可以为空2、blank=True django的Admin中添加数据时是否可允许空值3、primary_key = False 主键，对AutoField设置主键后，就会代替原来的自增 id 列4、auto_now 和 auto_now_add auto_now 自动创建---无论添加或修改，都是当前操作的时间 auto_now_add 自动创建---永远是创建时的时间5、choicesGENDER_CHOICE = ( (u&apos;M&apos;, u&apos;Male&apos;), (u&apos;F&apos;, u&apos;Female&apos;), )gender = models.CharField(max_length=2,choices = GENDER_CHOICE)6、max_length7、default 默认值8、verbose_name Admin中字段的显示名称9、name|db_column 数据库中的字段名称10、unique=True 不允许重复11、db_index = True 数据库索引12、editable=True 在Admin里是否可编辑13、error_messages=None 错误提示14、auto_created=False 自动创建15、help_text 在Admin中提示帮助信息16、validators=[]17、upload-to 上传到哪个位置,更多与image,filepath配合使用 连表结构一对多:models.ForeignKey(其他表)多对多:models.ManyToManyField(其他表)一对一:models.OneToOneField(其他表)应用场景:一对多：当一张表中创建一行数据时，有一个单选的下拉框（可以被重复选择）多对多：在某表中创建一行数据是，有一个可以多选的下拉框一对一：在某表中创建一行数据时，有一个单选的下拉框（下拉框中的内容被用过一次就消失了） 表操作基本操作12345678910111213141516171819# 增models.Tb1.objects.create(c1=&apos;xx&apos;, c2=&apos;oo&apos;) 增加一条数据，可以接受字典类型数据 **kwargs或obj = models.Tb1(c1=&apos;xx&apos;, c2=&apos;oo&apos;)obj.save()# 查models.Tb1.objects.get(id=123) # 获取单条数据，不存在则报错（不建议）models.Tb1.objects.all() # 获取全部models.Tb1.objects.filter(name=&apos;seven&apos;) # 获取指定条件的数据# 删models.Tb1.objects.filter(name=&apos;seven&apos;).delete() # 删除指定条件的数据# 改models.Tb1.objects.filter(name=&apos;seven&apos;).update(gender=&apos;0&apos;) # 将指定条件的数据更新，均支持 **kwargsobj = models.Tb1.objects.get(id=1)obj.c1 = &apos;111&apos;obj.save() # 修改单条数据 进阶操作123456789101112131415161718192021222324252627282930313233343536# 获取个数models.Tb1.objects.filter(name=&apos;seven&apos;).count()# 大于，小于models.Tb1.objects.filter(id__gt=1) # 获取id大于1的值models.Tb1.objects.filter(id__lt=10) # 获取id小于10的值models.Tb1.objects.filter(id__lt=10, id__gt=1) # 获取id大于1 且 小于10的值# inmodels.Tb1.objects.filter(id__in=[11, 22, 33]) # 获取id等于11、22、33的数据models.Tb1.objects.exclude(id__in=[11, 22, 33]) # not in# containsmodels.Tb1.objects.filter(name__contains=&quot;ven&quot;)models.Tb1.objects.filter(name__icontains=&quot;ven&quot;) # icontains大小写不敏感models.Tb1.objects.exclude(name__icontains=&quot;ven&quot;)# rangemodels.Tb1.objects.filter(id__range=[1, 2]) # 范围bettwen and# 其他类似# startswith，istartswith, endswith, iendswith,# order bymodels.Tb1.objects.filter(name=&apos;seven&apos;).order_by(&apos;id&apos;) # ascmodels.Tb1.objects.filter(name=&apos;seven&apos;).order_by(&apos;-id&apos;) # desc# limit 、offsetmodels.Tb1.objects.all()[10:20]# group by 去重 values(&apos;id&apos;)在annotate前面就是为了根据id生成group by#需要固定导入,称为聚合函数from django.db.models import Count, Min, Max, Summodels.Tb1.objects.filter(c1=1).values(&apos;id&apos;).annotate(c=Count(&apos;num&apos;))moddels.Tb1.objects.filter(c1=1).values(&apos;id&apos;).annotate(c=Count(&apos;id&apos;)).values(&apos;id&apos;&apos;,&apos;name&apos;)# SELECT &quot;app01_tb1&quot;.&quot;id&quot;, COUNT(&quot;app01_tb1&quot;.&quot;num&quot;) AS &quot;c&quot; FROM &quot;app01_tb1&quot; WHERE &quot;app01_tb1&quot;.&quot;c1&quot; = 1 GROUP BY &quot;app01_tb1&quot;.&quot;id&quot; 参考资料Django之model详解]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos6.5升级glibc2.12到2.15]]></title>
      <url>%2F2017%2F04%2F05%2Fshell%2FCentos6.5%E5%8D%87%E7%BA%A7glibc2.12%E5%88%B02.15%2F</url>
      <content type="text"><![CDATA[&ensp;&ensp;Centos6.5默认的 glibc版本最高为2.12， 而在进行一些开发时项目所依赖的包往往需要更高版本的glibc库支持，因此在不升级系统的前提下， 需要主动更新系统glibc库。 一般遇到错误libc.so.6: version GLIBC_2.15 not found时表示需要对glibc进行升级了。 查看系统glibc支持的版本1234567891011121314151617181920strings /lib64/libc.so.6 | grep GLIBC GLIBC_2.2.5 GLIBC_2.2.6 GLIBC_2.3 GLIBC_2.3.2 GLIBC_2.3.3 GLIBC_2.3.4 GLIBC_2.4 GLIBC_2.5 GLIBC_2.6 GLIBC_2.7 GLIBC_2.8 GLIBC_2.9 GLIBC_2.10 GLIBC_2.11 GLIBC_2.12 GLIBC_PRIVATE# 查看当前glibc的版本ll /lib64/libc.so.6 lrwxrwxrwx. 1 root root 12 Oct 9 2014 /lib64/libc.so.6 -&gt; libc-2.12.so 安装升级glibc1234567cd /usr/local/src/wget http://mirror.bjtu.edu.cn/gnu/glibc/glibc-2.15.tar.gztar xf glibc-2.15.tar.gzmkdir buildcd build/../glibc-2.15/configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/binmake &amp;&amp; make install 验证12345678910111213141516171819202122strings /lib64/libc.so.6 | grep GLIBC GLIBC_2.2.5 GLIBC_2.2.6 GLIBC_2.3 GLIBC_2.3.2 GLIBC_2.3.3 GLIBC_2.3.4 GLIBC_2.4 GLIBC_2.5 GLIBC_2.6 GLIBC_2.7 GLIBC_2.8 GLIBC_2.9 GLIBC_2.10 GLIBC_2.11 GLIBC_2.12 GLIBC_2.13 GLIBC_2.14 GLIBC_2.15 GLIBC_PRIVATEll /lib64/libc.so.6 lrwxrwxrwx 1 root root 12 4月 4 03:11 /lib64/libc.so.6 -&gt; libc-2.15.so 误删libc.so.6解决办法1LD_PRELOAD=/lib/libc-2.12.so ln -s /lib/libc-2.12.so lib/libc.so.6 参考资料CentOS6.5系统”libc.so.6: version ‘GLIBC_2.15’ not found”解决方法Centos6.5升级glibc过程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos6.5安装vim自动补全插件YouCompleteMe]]></title>
      <url>%2F2017%2F04%2F01%2Fshell%2FCentos6.5%E5%AE%89%E8%A3%85vim%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8%E6%8F%92%E4%BB%B6YouCompleteMe%2F</url>
      <content type="text"><![CDATA[&ensp;&ensp;YouCompleteMe的安装是比较麻烦的，特别是最新版本对依赖要求比较高，而centos6.5自带的版本都比较低，不符合要求，需要手动升级。安装主页有详细介绍(YouCompleteMe安装)。 安装前提&ensp;&ensp;首先，YouCompleteMe要求Vim版本7.4.143+，而且vim须支持Python，可以在vim中：version查看，如果python前面有+号表示支持，否则就是不支持。如果不支持则需要重新编译安装vim。同时clang版本为3.9以上。其次，YouCompleteMe对gcc要求支持c++11特性，所以需要升级gcc版本(Centos6.5升级gcc4.4.7到4.8.2)。 安装vundle&ensp;&ensp;vundle是一个vim插件管理工具，它可以让你让你可以非常轻松地安装、更新、搜索和清理Vim插件。123456789101112131415161718192021222324252627282930313233343536git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle# 在~/.vimrc中配置set nocompatible " be iMproved, requiredfiletype off " required " set the runtime path to include Vundle and initializeset rtp+=~/.vim/bundle/vundle/call vundle#rc()" alternatively, pass a path where Vundle should install plugins"let path = '~/some/path/here'"call vundle#rc(path) " let Vundle manage Vundle, requiredPlugin 'gmarik/vundle' " The following are examples of different formats supported." Keep Plugin commands between here and filetype plugin indent on." scripts on GitHub reposPlugin 'tpope/vim-fugitive'Plugin 'Lokaltog/vim-easymotion'Plugin 'tpope/vim-rails.git'" The sparkup vim script is in a subdirectory of this repo called vim." Pass the path to set the runtimepath properly.Plugin 'rstacruz/sparkup', &#123;'rtp': 'vim/'&#125;" scripts from http://vim-scripts.org/vim/scripts.htmlPlugin 'L9'Plugin 'FuzzyFinder'" scripts not on GitHubPlugin 'git://git.wincent.com/command-t.git'" git repos on your local machine (i.e. when working on your own plugin)Plugin 'file:///home/gmarik/path/to/plugin'" ... filetype plugin indent on " requiredBundle 'Valloric/YouCompleteMe'# 打开vim，输入:BundleInstall进行安装，+号表示已经安装，&gt;表示正在安装 升级clang&ensp;&ensp;如果不升级clang，安装YouCompleteMe时将会报以下错误：&ensp;&ensp;centos6.5自带cmake版本为2.8.12，而clang3.9.1编译依赖于更高版本的cmake，所以需要先升级cmake(Centos6.5升级cmake2.8.12到3.6.0)。123456789101112131415161718192021222324252627282930# clang source codewget http://releases.llvm.org/3.9.1/cfe-3.9.1.src.tar.xz# llvm source codewget http://releases.llvm.org/3.9.1/llvm-3.9.1.src.tar.xz# compiler RT source codewget http://releases.llvm.org/3.9.1/compiler-rt-3.9.1.src.tar.xz# clang tools extrawget http://releases.llvm.org/3.9.1/clang-tools-extra-3.9.1.src.tar.xztar xf cfe-3.9.1.src.tar.xztar xf llvm-3.9.1.src.tar.xztar xf compiler-rt-3.9.1.src.tar.xztar xf clang-tools-extra-3.9.1.src.tar.xzmv cfe-3.9.1.src clangmv clang llvm-3.9.1.src/tools/mv clang-tools-extra-3.9.1.src extramv extra/ llvm-3.9.1.src/tools/clang/mv compiler-rt-3.9.1.src compiler-rtmv compiler-rt llvm-3.9.1.src/projects/mkdir buildcd build/# 编译安装需要python2.7+版本，可以通过pyenv配置多版本Python环境，在build和src目录执行pyenv local 2.7.6cmake -G "Unix Makefiles" -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local/clang3.9.1 -DLLVM_OPTIMIZED_TABLEGEN=1 ../llvm-3.9.1.srcmake &amp;&amp; make install/usr/local/clang3.9.1/bin/clang -v clang version 3.9.1 (tags/RELEASE_391/final) Target: x86_64-unknown-linux-gnu Thread model: posix InstalledDir: /usr/local/clang3.9.1/bin Found candidate GCC installation: /usr/lib/gcc/x86_64-redhat-linux/4.4.4 Found candidate GCC installation: /usr/lib/gcc/x86_64-redhat-linux/4.4.7 安装YouCompleteMe1234cd ~/.vim/bundle/YouCompleteMe/pyenv local 2.7.6# 参数是为了支持c/c++的补全./install.sh --clang-complete &ensp;&ensp;安装时如果出现以下错误，只需要按照提示操作即可，由于我这边是通过pyenv设置Python，需先卸载之前版本，再设置一个环境变量后重新安装即可。123456pyenv uninstall 2.7.6cat &gt;&gt; ~/.bashrc &lt;&lt; EOFexport PYTHON_CONFIGURE_OPTS="--enable-shared"EOF. ~/.bashrcpyenv install 2.7.6 配置YouCompleteMe&ensp;&ensp;YouCompleteMe进行补全时需要查找一个 ycm_global_ycm_extra_conf文件。可以每次在工作目录中放置这个文件，也可以设置全局。全局设置要在.vimrc中添加一行即可。(let g:ycm_global_ycm_extra_conf = ‘~/.vim/bundle/YouCompleteMe/third_party/ycmd/examples/.ycm_extra_conf.py’)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354cp ~/.vim/bundle/YouCompleteMe/third_party/ycmd/examples/.ycm_extra_conf.py ~/# 配置.vimrc文件set nu set nocompatible syntax on set tabstop=3 set softtabstop=3 set shiftwidth=3 set autoindent set cindent set cinoptions=&#123;0,1s,t0,n-2,p2s,(03s,=.5s,&gt;1s,=1s,:1s set rtp+=~/.vim/bundle/vundle/ call vundle#rc() " Install YouCompleteMe Bundle 'Valloric/YouCompleteMe' " #####YouCompleteMe Configure let g:ycm_global_ycm_extra_conf = '~/.ycm_extra_conf.py' " 自动补全配置 set completeopt=longest,menu "让Vim的补全菜单行为与一般IDE一致(参考VimTip1228) autocmd InsertLeave * if pumvisible() == 0|pclose|endif "离开插入模式后自动关闭预览窗口 inoremap &lt;expr&gt; &lt;CR&gt; pumvisible() ? "\&lt;C-y&gt;" : "\&lt;CR&gt;" "回车即选中当前项 "上下左右键的行为 会显示其他信息 inoremap &lt;expr&gt; &lt;Down&gt; pumvisible() ? "\&lt;C-n&gt;" : "\&lt;Down&gt;" inoremap &lt;expr&gt; &lt;Up&gt; pumvisible() ? "\&lt;C-p&gt;" : "\&lt;Up&gt;" inoremap &lt;expr&gt; &lt;PageDown&gt; pumvisible() ? "\&lt;PageDown&gt;\&lt;C-p&gt;\&lt;C-n&gt;" : "\&lt;PageDown&gt;" inoremap &lt;expr&gt; &lt;PageUp&gt; pumvisible() ? "\&lt;PageUp&gt;\&lt;C-p&gt;\&lt;C-n&gt;" : "\&lt;PageUp&gt;" "youcompleteme 默认tab s-tab 和自动补全冲突 "let g:ycm_key_list_select_completion=['&lt;c-n&gt;'] let g:ycm_key_list_select_completion = ['&lt;Down&gt;'] "let g:ycm_key_list_previous_completion=['&lt;c-p&gt;'] let g:ycm_key_list_previous_completion = ['&lt;Up&gt;'] let g:ycm_confirm_extra_conf=0 "关闭加载.ycm_extra_conf.py提示 let g:ycm_collect_identifiers_from_tags_files=1 " 开启 YCM 基于标签引擎 let g:ycm_min_num_of_chars_for_completion=2 " 从第2个键入字符就开始罗列匹配项 let g:ycm_cache_omnifunc=0 " 禁止缓存匹配项,每次都重新生成匹配项 let g:ycm_seed_identifiers_with_syntax=1 " 语法关键字补全 nnoremap &lt;F5&gt; :YcmForceCompileAndDiagnostics&lt;CR&gt; "force recomile with syntastic "nnoremap &lt;leader&gt;lo :lopen&lt;CR&gt; "open locationlist "nnoremap &lt;leader&gt;lc :lclose&lt;CR&gt; "close locationlist inoremap &lt;leader&gt;&lt;leader&gt; &lt;C-x&gt;&lt;C-o&gt; "在注释输入中也能补全 let g:ycm_complete_in_comments = 1 "在字符串输入中也能补全 let g:ycm_complete_in_strings = 1 "注释和字符串中的文字也会被收入补全 let g:ycm_collect_identifiers_from_comments_and_strings = 0 let g:clang_user_options='|| exit 0' nnoremap &lt;leader&gt;jd :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt; " 跳转到定义处 " #####YouCompleteMe Configure 效果&ensp;&ensp;在测试效果时，发现不能提示关键字，而且在补全时会出现前面输入的字符丢失。通过查看日志(youcompleteme日志位于/tmp/目录下)发现glibc版本过低，遂升级glibc(Centos6.5升级glibc2.12到2.15)。 最终效果 参考资料linux YouCompleteMe 安装和使用笔记YouCompleteMe安装与配置vim配置及插件安装管理clang 3.9.1 centos 7 编译安装]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos6.5升级cmake2.8.12到3.6.0]]></title>
      <url>%2F2017%2F03%2F31%2Fshell%2FCentos6.5%E5%8D%87%E7%BA%A7cmake2.8.12%E5%88%B03.6.0%2F</url>
      <content type="text"><![CDATA[安装依赖cmake3.6.0依赖于更高版本的gcc，需先升级gcc(Centos6.5升级gcc4.4.7到4.8.2)。1yum install ncurses-devel 安装cmake12345wget https://cmake.org/files/v3.6/cmake-3.6.0.tar.gztar xf cmake-3.6.0.tar.gzcd cmake-3.6.0./configuremake &amp;&amp; make install 注意： 在configure时如果报以下错误，是由于缺少GLIBCXX__3.4.15版本或更高版本，通过strings命令查看是否包含此版本，如果没有，由于之前升级过gcc，查找到最新的libstdc++将旧的覆盖的：1234567891011121314151617181920212223242526272829303132333435363738394041424344strings /usr/lib64/libstdc++.so.6 |grep GLIBCXX GLIBCXX_3.4 GLIBCXX_3.4.1 GLIBCXX_3.4.2 GLIBCXX_3.4.3 GLIBCXX_3.4.4 GLIBCXX_3.4.5 GLIBCXX_3.4.6 GLIBCXX_3.4.7 GLIBCXX_3.4.8 GLIBCXX_3.4.9 GLIBCXX_3.4.10 GLIBCXX_3.4.11 GLIBCXX_3.4.12 GLIBCXX_3.4.13 GLIBCXX_FORCE_NEW GLIBCXX_DEBUG_MESSAGE_LENGTHcp /usr/local/lib64/libstdc++.so.6.0.18 /usr/lib64/cd /usr/lib64/cp libstdc++.so.6 libstdc++.so.6.bakcp libstdc++.so.6.0.18 libstdc++.so.6strings libstdc++.so.6|grep GLIBCXX GLIBCXX_3.4 GLIBCXX_3.4.1 GLIBCXX_3.4.2 GLIBCXX_3.4.3 GLIBCXX_3.4.4 GLIBCXX_3.4.5 GLIBCXX_3.4.6 GLIBCXX_3.4.7 GLIBCXX_3.4.8 GLIBCXX_3.4.9 GLIBCXX_3.4.10 GLIBCXX_3.4.11 GLIBCXX_3.4.12 GLIBCXX_3.4.13 GLIBCXX_3.4.14 GLIBCXX_3.4.15 GLIBCXX_3.4.16 GLIBCXX_3.4.17 GLIBCXX_3.4.18 GLIBCXX_3.4.19 GLIBCXX_FORCE_NEW GLIBCXX_DEBUG_MESSAGE_LENGTH 添加环境变量123456cat &gt;&gt; /etc/profile &lt;&lt; EOF#cmake toolsPATH=/home/operation/cmake-3.6.0/bin:$PATHexport PATHEOF. /etc/profile 验证123cmake --version cmake version 3.6.0 CMake suite maintained and supported by Kitware (kitware.com/cmake). 参考资料centos 6.5下cmake工具的安装与配置CentOS-6.3安装配置cmake‘GLIBCXX_3.4.15’ not found错误]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos6.5升级gcc4.4.7到4.8.2]]></title>
      <url>%2F2017%2F03%2F30%2Fshell%2Fcentos6.5%E5%8D%87%E7%BA%A7gcc4.4.7%E5%88%B04.8.2%2F</url>
      <content type="text"><![CDATA[由于centos6.5自带的gcc4.4.7不能支持c++11的特性，所以希望升级到4.8.2。 下载源码安装包12wget http://ftp.gnu.org/gnu/gcc/gcc-4.8.2/gcc-4.8.2.tar.bz2tar -jxvf gcc-4.8.2.tar.bz2 下载编译所需依赖12cd gcc-4.8.2./contrib/download_prerequisites 建立目录供编译输出12mkdir gcc-build-4.8.2cd gcc-build-4.8.2 生成Makefile文件1../configure -enable-checking=release -enable-languages=c,c++ -disable-multilib 编译安装1make &amp;&amp; make install 验证12345678[root@localhost gcc-build-4.8.2]# gcc -v使用内建 specs。COLLECT_GCC=gccCOLLECT_LTO_WRAPPER=/usr/local/libexec/gcc/x86_64-unknown-linux-gnu/4.8.2/lto-wrapper目标：x86_64-unknown-linux-gnu配置为：../configure -enable-checking=release -enable-languages=c,c++ -disable-multilib线程模型：posixgcc 版本 4.8.2 (GCC) 参考资料CentOS6.5手动升级gcc4.8.2CentOS6.6升级gcc4.8教程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django book学习笔记(二)——模板]]></title>
      <url>%2F2017%2F03%2F28%2Fdjango%2FDjango_book%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)%E2%80%94%E2%80%94%E6%A8%A1%E6%9D%BF%2F</url>
      <content type="text"><![CDATA[模板系统的基本知识模板是一个文本，用于分离文档的表现形式和内容。 模板定义了占位符以及各种用于规范文档该如何显示的各部分基本逻辑（模板标签）。 模板通常用于产生HTML，但是Django的模板也能产生任何基于文本格式的文档。 如何使用模板系统在Python代码中使用Django模板的最基本方式如下：1).可以用原始的模板代码字符串创建一个 Template 对象， Django同样支持用指定模板文件路径的方式来创建 Template 对象;2).调用模板对象的render方法，并且传入一套变量context。它将返回一个基于模板的展现字符串，模板中的变量和标签会被context值替换。例： 12345678&gt;&gt;&gt; from django import template&gt;&gt;&gt; t = template.Template('My name is &#123;&#123; name &#125;&#125;.')&gt;&gt;&gt; c = template.Context(&#123;'name': 'Adrian'&#125;)&gt;&gt;&gt; print t.render(c)My name is Adrian.&gt;&gt;&gt; c = template.Context(&#123;'name': 'Fred'&#125;)&gt;&gt;&gt; print t.render(c)My name is Fred. 深度变量的查找在 Django 模板中遍历复杂数据结构的关键是句点字符 (.)。比如，假设你要向模板传递一个 Python 字典。 要通过字典键访问该字典的值，可使用一个句点： 123456&gt;&gt;&gt; from django.template import Template, Context&gt;&gt;&gt; person = &#123;'name': 'Sally', 'age': '43'&#125;&gt;&gt;&gt; t = Template('&#123;&#123; person.name &#125;&#125; is &#123;&#123; person.age &#125;&#125; years old.')&gt;&gt;&gt; c = Context(&#123;'person': person&#125;)&gt;&gt;&gt; t.render(c)u'Sally is 43 years old.' 同样，也可以通过句点来访问对象的属性。点语法也可以用来引用对象的方法。最后，句点也可用于访问列表索引。句点查找规则可概括为： 当模板系统在变量名中遇到点时，按照以下顺序尝试进行查找： 字典类型查找 （比如 foo[“bar”] ) 属性查找 (比如 foo.bar ) 方法调用 （比如 foo.bar() ) 列表类型索引查找 (比如 foo[bar] ) 系统使用所找到的第一个有效类型。 这是一种短路逻辑。注意： 调用方法时不需要使用圆括号，而且也无法给该方法传递参数；你只能调用不需参数的方法。 在方法查找过程中，如果某方法抛出一个异常，如果该异常有一个 silent_variable_failure 属性并且值为 True，则模板里的指定变量会被置为空字符串。 如果模板文件里包含了 ，对象又具有 delete()方法，而且delete() 有alters_data=True这个属性，那么在模板载入时， delete()方法将不会被执行。 它将静静地错误退出。 基本的模板标签和过滤器1).if/else {% if %} 标签检查(evaluate)一个变量，如果这个变量为真(即，变量存在，非空，不是布尔值假)，系统会显示在 {% if %} 和 {% endif %} 之间的任何内容，例如： 12345&#123;% if today_is_weekend %&#125; &lt;p&gt;Welcome to the weekend!&lt;/p&gt;&#123;% else %&#125; &lt;p&gt;Get back to work.&lt;/p&gt;&#123;% endif %&#125; {% if %} 标签接受 and ， or 或者 not 关键字来对多个变量做判断 ，或者对变量取反（ not )，但是{% if %} 标签不允许在同一个标签中同时使用 and 和 or ，因为逻辑上可能模糊的。而且没有 {% elif %} 标签， 请使用嵌套的{% if %}标签来达成同样的效果。一定要用 {% endif %} 关闭每一个 {% if %} 标签。 2).for {% for %} 允许我们在一个序列上迭代。每一次循环中，模板系统会渲染在 {% for %} 和 {% endfor %} 之间的所有内容。 给标签增加一个reversed使得该列表被反向迭代。 123&#123;% for athlete in athlete_list reversed %&#125;...&#123;% endfor %&#125; for标签支持一个可选的{% empty %}分句，通过它我们可以定义当列表为空时的输出内容。 12345&#123;% for athlete in athlete_list %&#125; &lt;p&gt;&#123;&#123; athlete.name &#125;&#125;&lt;/p&gt;&#123;% empty %&#125; &lt;p&gt;There are no athletes. Only computer programmers.&lt;/p&gt;&#123;% endfor %&#125; 在每个{% for %}循环里有一个称为forloop的模板变量。这个变量有一些提示循环进度信息的属性。 forloop.counter 总是一个表示当前循环的执行次数的整数计数器。 这个计数器是从1开始的，所以在第一次循环时 forloop.counter 将会被设置为1。 123&#123;% for item in todo_list %&#125; &lt;p&gt;&#123;&#123; forloop.counter &#125;&#125;: &#123;&#123; item &#125;&#125;&lt;/p&gt;&#123;% endfor %&#125; forloop.counter0 类似于 forloop.counter ，但是它是从0计数的。 第一次执行循环时这个变量会被设置为0。 forloop.revcounter 是表示循环中剩余项的整型变量。 在循环初次执行时 forloop.revcounter 将被设置为序列中项的总数。 最后一次循环执行中，这个变量将被置1。 forloop.revcounter0 类似于 forloop.revcounter ，但它以0做为结束索引。在第一次执行循环时，该变量会被置为序列的项的个数减1。 forloop.first 是一个布尔值。 在第一次执行循环时该变量为True，在下面的情形中这个变量是很有用的。 12345&#123;% for object in objects %&#125; &#123;% if forloop.first %&#125;&lt;li class=&quot;first&quot;&gt;&#123;% else %&#125;&lt;li&gt;&#123;% endif %&#125; &#123;&#123; object &#125;&#125; &lt;/li&gt;&#123;% endfor %&#125; forloop.last 是一个布尔值；在最后一次执行循环时被置为True。 一个常见的用法是在一系列的链接之间放置管道符(|) 1&#123;% for link in links %&#125;&#123;&#123; link &#125;&#125;&#123;% if not forloop.last %&#125; | &#123;% endif %&#125;&#123;% endfor %&#125; forloop.parentloop 是一个指向当前循环的上一级循环的 forloop 对象的引用（在嵌套循环的情况下）。 3).ifequal/ifnotequal {% ifequal %} 标签比较两个值，当他们相同时，显示在 {% ifequal %} 和 {% endifequal %} 之中所有的值。和 {% if %} 类似， {% ifequal %} 支持可选的 {% else%} 标签。 12345&#123;% ifequal section &apos;sitenews&apos; %&#125; &lt;h1&gt;Site News&lt;/h1&gt;&#123;% else %&#125; &lt;h1&gt;No News Here&lt;/h1&gt;&#123;% endifequal %&#125; 只有模板变量，字符串，整数和小数可以作为 {% ifequal %} 标签的参数。 1234&#123;% ifequal variable 1 %&#125;&#123;% ifequal variable 1.23 %&#125;&#123;% ifequal variable &apos;foo&apos; %&#125;&#123;% ifequal variable &quot;foo&quot; %&#125; 其他的一些类型，例如Python的字典类型、列表类型、布尔类型，不能用在 {% ifequal %} 中。下面是些错误的例子： 123&#123;% ifequal variable True %&#125;&#123;% ifequal variable [1, 2, 3] %&#125;&#123;% ifequal variable &#123;&apos;key&apos;: &apos;value&apos;&#125; %&#125; 注释Django模板语言同样提供代码注释。 注释使用 ，但这种语法的注释不能跨越多行：1&#123;# This is a comment #&#125; 如果要实现多行注释，可以使用{% comment %}模板标签，就像这样： 1234&#123;% comment %&#125;This is amulti-line comment.&#123;% endcomment %&#125; 过滤器模板过滤器是在变量被显示前修改它的值的一个简单方法。 过滤器使用管道字符，如下所示：1&#123;&#123; name|lower &#125;&#125; 有些过滤器有参数。 过滤器的参数跟随冒号之后并且总是以双引号包含。 例如：1&#123;&#123; bio|truncatewords:&quot;30&quot; &#125;&#125; 以下几个是最为重要的过滤器的一小部分。 addslashes : 添加反斜杠到任何反斜杠、单引号或者双引号前面。 date : 按指定的格式字符串参数格式化 date 或者 datetime 对象。 length : 返回变量的长度。 对于列表，这个参数将返回列表元素的个数。 对于字符串，这个参数将返回字符串中字符的个数。 你可以对列表或者字符串，或者任何知道怎么测定长度的Python 对象使用这个方法（也就是说，有 len() 方法的对象）。 在视图中使用模板1).模板加载打开settings.py配置文件，找到TEMPLATE_DIRS添加一个目录用于存放模板文件，例如：123TEMPLATE_DIRS = ( &apos;/home/django/mysite/templates&apos;,) 完成 TEMPLATE_DIRS 设置后，下一步就是修改视图代码，让它使用 Django 模板加载功能而不是对模板路径硬编码。例：12345678910from django.template.loader import get_templatefrom django.template import Contextfrom django.http import HttpResponseimport datetimedef current_datetime(request): now = datetime.datetime.now() t = get_template('current_datetime.html') html = t.render(Context(&#123;'current_date': now&#125;)) return HttpResponse(html) get_template()方法会自动为你连接已经设置的TEMPLATE_DIRS目录和你传入该法的模板名称参数，在文件系统中找出模块的位置，打开文件并返回一个编译好的 Template 对象。2).render_to_response()Django提供了一个捷径，让你一次性地载入某个模板文件，渲染它，然后将此作为HttpResponse返回。该捷径就是位于django.shortcuts模块中名为render_to_response() 的函数，大多数情况下，你会使用render_to_response()而不是手动加载模板并创建Context和HttpResponse对象。render_to_response() 的第一个参数必须是要使用的模板名称。 如果要给定第二个参数，那么该参数必须是为该模板创建 Context 时所使用的字典。 如果不提供第二个参数， render_to_response() 使用一个空字典。123456from django.shortcuts import render_to_responseimport datetimedef current_datetime(request): now = datetime.datetime.now() return render_to_response('current_datetime.html', &#123;'current_date': now&#125;) include模板标签 该标签允许在（模板中）包含其它的模板的内容。 标签的参数是所要包含的模板名称，可以是一个变量，也可以是用单/双引号硬编码的字符串。 每当在多个模板中出现相同的代码时，就应该考虑是否要使用 {% include %} 来减少重复。 1234567891011121314# mypage.html&lt;html&gt;&lt;body&gt;&#123;% include &quot;includes/nav.html&quot; %&#125;&lt;h1&gt;&#123;&#123; title &#125;&#125;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;# includes/nav.html&lt;div id=&quot;nav&quot;&gt; You are in: &#123;&#123; current_section &#125;&#125;&lt;/div&gt; 模板继承模板继承就是先构造一个基础框架模板，而后在其子模板中对它所包含站点公用部分和定义块进行重载。12345678910111213141516#base.html&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot;&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;My helpful timestamp site&lt;/h1&gt; &#123;% block content %&#125;&#123;% endblock %&#125; &#123;% block footer %&#125; &lt;hr&gt; &lt;p&gt;Thanks for visiting my site.&lt;/p&gt; &#123;% endblock %&#125;&lt;/body&gt;&lt;/html&gt; 我们使用一个以前已经见过的模板标签： {% block %} 。 所有的 {% block %} 标签告诉模板引擎，子模板可以重载这些部分。每个{% block %}标签所要做的是告诉模板引擎，该模板下的这一块内容将有可能被子模板覆盖。 123456789#current_datetime.html &#123;% extends &quot;base.html&quot; %&#125;&#123;% block title %&#125;The current time&#123;% endblock %&#125;a% block content %&#125;&lt;p&gt;It is now &#123;&#123; current_date &#125;&#125;.&lt;/p&gt;&#123;% endblock %&#125; 在加载 current_datetime.html 模板时，模板引擎发现了 {% extends %} 标签， 注意到该模板是一个子模板。模板引擎立即装载其父模板，即base.html 。此时，模板引擎注意到 base.html 中的三个 {% block %} 标签，并用子模板的内容替换这些 block 。因此，引擎将会使用我们在 { block title %} 中定义的标题，对 {% block content %} 也是如此。 所以，网页标题一块将由 {% block title %}替换，同样地，网页的内容一块将由 {% block content %}替换。以下是使用模板继承的一些诀窍： 如果在模板中使用 {% extends %} ，必须保证其为模板中的第一个模板标记。 否则，模板继承将不起作用。 一般来说，基础模板中的 {% block %} 标签越多越好。记住，子模板不必定义父模板中所有的代码块，因此你可以用合理的缺省值对一些代码块进行填充，然后只对子模板所需的代码块进行（重）定义。 俗话说，钩子越多越好。 如果发觉自己在多个模板之间拷贝代码，你应该考虑将该代码段放置到父模板的某个 {% block %} 中。 如果你需要访问父模板中的块的内容，使用 {{ block.super }}这个标签吧，这一个魔法变量将会表现出父模板中的内容。 如果只想在上级代码块基础上添加内容，而不是全部重载，该变量就显得非常有用了。 不可同一个模板中定义多个同名的 {% block %} 。存在这样的限制是因为block 标签的工作方式是双向的。也就是说，block 标签不仅挖了一个要填的坑，也定义了在父模板中这个坑所填充的内容。 如果模板中出现了两个相同名称的 {% block %} 标签，父模板将无从得知要使用哪个块的内容。 {% extends %} 对所传入模板名称使用的加载方法和 get_template() 相同。 也就是说，会将模板名称被添加到 TEMPLATE_DIRS 设置之后。 多数情况下，{% extends %} 的参数应该是字符串，但是如果直到运行时方能确定父模板名，这个参数也可以是个变量。 这使得你能够实现一些很酷的动态功能。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django book学习笔记(一)——视图和url配置]]></title>
      <url>%2F2017%2F03%2F24%2Fdjango%2FDjango_book%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)%E2%80%94%E2%80%94%E8%A7%86%E5%9B%BE%E5%92%8Curl%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[视图一个视图就是Python的一个函数，每个视图函数至少要有一个参数，通常被叫作request。 这是一个触发这个视图、包含当前Web请求信息的对象，是类django.http.HttpRequest的一个实例。它返回一个HttpResponse实例。为了使一个Python的函数成为一个Django可识别的视图，它必须满足这两个条件。(也有例外)例：1234from django.http import HttpResponse def hello(request): return HttpResponse("Hello World") URL配置1).URLconfURLconf就像是 Django 所支撑网站的目录。它的本质是 URL 模式以及要为该 URL 模式调用的视图函数之间的映射表。你就是以这种方式告诉 Django，对于这个 URL 调用这段代码，对于那个 URL 调用那段代码。12345678910111213141516171819from django.conf.urls import patterns, include, urlfrom mysite.views import hello # Uncomment the next two lines to enable the admin:# from django.contrib import admin# admin.autodiscover() urlpatterns = patterns('', # Examples: # url(r'^$', 'mysite.views.home', name='home'), # url(r'^mysite/', include('mysite.foo.urls')), # Uncomment the admin/doc line below to enable admin documentation: # url(r'^admin/doc/', include('django.contrib.admindocs.urls')), # Uncomment the next line to enable the admin: # url(r'^admin/', include(admin.site.urls)), (r'^hello/$',hello),) 2).URL配置和松耦合在Django的应用程序中，URL的定义和视图函数之间是松耦合的，换句话说，决定URL返回哪个视图函数和实现这个视图函数是在两个不同的地方。这使得 开发人员可以修改一块而不会影响另一块。3).动态URL我们使用圆括号把参数在URL模式里标识出来。在这个例子中，我们想要把这些数字作为参数，用圆括号把 \d{1,2} 包围起来：1(r'^time/plus/(\d&#123;1,2&#125;)/$', hours_ahead), 对应视图函数：1234567891011from django.http import Http404, HttpResponseimport datetime def hours_ahead(request, offset): try: offset = int(offset) except ValueError: raise Http404() dt = datetime.datetime.now() + datetime.timedelta(hours=offset) html = "&lt;html&gt;&lt;body&gt;In %s hour(s), it will be %s.&lt;/body&gt;&lt;/html&gt;" % (offset, dt) return HttpResponse(html) 解释：offset 是从匹配的URL里提取出来的。 例如：如果请求URL是/time/plus/3/，那么offset将会是3；如果请求URL是/time/plus/21/，那么offset将会是21。请注意：捕获值永远都是字符串（string）类型，而不会是整数（integer）类型，即使这个字符串全由数字构成（如：“21”）。4).URL中常用的正则表达式 Django处理请求过程1).进来的请求转入/hello/.2).Django通过在ROOT_URLCONF配置来决定根URLconf.3).Django在URLconf中的所有URL模式中，查找第一个匹配/hello/的条目。4).如果找到匹配，将调用相应的视图函数5).视图函数返回一个HttpResponse6.)Django转换HttpResponse为一个适合的HTTP response， 以Web page显示出来]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[新的开始]]></title>
      <url>%2F2017%2F03%2F21%2F%E6%96%B0%E7%9A%84%E5%BC%80%E5%A7%8B%2F</url>
      <content type="text"><![CDATA[无论你从什么时候开始，重要的是开始后就不要停止。无论你从什么时候结束，重要的是结束后就不要悔恨。]]></content>
    </entry>

    
  
  
</search>
